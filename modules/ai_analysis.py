"""
Module: AI Analysis Engine (Microsoft AI-only)
Classifies uploaded media into:
- ğŸŸ¢ Real & Safe
- ğŸ”´ Deepfake / Manipulated
- ğŸŸ¡ Real but Sensitive (Private)
Uses Microsoft Foundry / Azure AI exclusively. No local ML models are referenced.
"""

import os
import io
import requests
from typing import Dict, Any
from PIL import Image
from .deepfake_analyzer import DeepfakeAnalyzer
from .download_datasets import ensure_datasets


# Ensure CSV datasets are present (no-op if already downloaded)
try:
    ensure_datasets()
except Exception as _e:
    print(f"Warning: dataset downloader failed: {_e}")


class AIAnalysisEngine:
    """Microsoft AI-powered analysis engine for media classification"""

    def __init__(self):
        # Azure / Foundry credentials from environment
        self.azure_language_key = os.getenv("AZURE_LANGUAGE_KEY")
        self.azure_language_endpoint = os.getenv("AZURE_LANGUAGE_ENDPOINT")
        self.azure_content_safety_key = os.getenv("AZURE_CONTENT_SAFETY_KEY")
        self.azure_content_safety_endpoint = os.getenv("AZURE_CONTENT_SAFETY_ENDPOINT")

        print("Azure Language Endpoint:", self.azure_language_endpoint)
        print("Azure Content Safety Endpoint:", self.azure_content_safety_endpoint)
        # Deepfake analyzer instance - model is loaded once inside the module
        try:
            self.deepfake_analyzer = DeepfakeAnalyzer()
        except Exception:
            # Defensive: ensure analyzer initialization never breaks the pipeline
            self.deepfake_analyzer = None

    def analyze(self, media_data: Dict[str, Any],
                check_deepfake: bool = True,
                check_sensitive: bool = True) -> Dict[str, Any]:
        """
        Analyze media and return classification results using Microsoft AI.
        """
        image: Image.Image = media_data.get('image')
        if image is None:
            return {
                'classification': 'unknown',
                'confidence': 0.0,
                'details': {'error': 'No image data available'},
                'recommendations': []
            }

        # Ensure RGB format
        if image.mode != 'RGB':
            image = image.convert('RGB')

        # Convert image to bytes for API
        img_bytes = io.BytesIO()
        image.save(img_bytes, format='PNG')
        img_bytes = img_bytes.getvalue()

        results = {
            'deepfake_score': 0.0,
            'sensitive_score': 0.0,
            'manipulation_indicators': [],
            'sensitive_indicators': [],
            'foundry_used': False,
            'foundry_error': None
        }

        # ---- Deepfake / Manipulation Analysis ----
        if check_deepfake:
            # Use the independent deepfake analyzer module (must remain separate
            # from Azure Content Safety). Analyzer is defensive and will return
            # an explicit failure dict if something goes wrong.
            try:
                if self.deepfake_analyzer is None:
                    raise RuntimeError('Deepfake analyzer not initialized')

                df_res = self.deepfake_analyzer.analyze(image)

                # Store first-class deepfake result (normalized 0.0-1.0)
                results['deepfake'] = {
                    'label': df_res.get('label', 'unknown'),
                    'confidence': float(df_res.get('confidence', 0.0)),
                    'risk': float(df_res.get('risk', 0.0)),
                    'analysis_failed': bool(df_res.get('analysis_failed', False)),
                    'error': df_res.get('error')
                }

                # Backwards-compatible numeric fields used elsewhere in the app
                # (legacy code expects 0-100 scores under `deepfake_score`).
                try:
                    results['deepfake_score'] = float(results['deepfake']['risk']) * 100.0
                except Exception:
                    results['deepfake_score'] = 0.0

                # No manipulation indicators available from this adapter by default
                results['manipulation_indicators'] = []

            except Exception as e:
                results['foundry_error'] = f"Deepfake analyzer error: {e}"
                # Keep legacy numeric field to 0 to avoid breaking consumers
                results['deepfake_score'] = 0.0
                results['manipulation_indicators'] = []

        # ---- Sensitive Content Analysis ----
        if check_sensitive:
            sensitive_result = self._call_content_safety_api(img_bytes, analysis_type='sensitive')
            if 'error' in sensitive_result:
                results['foundry_error'] = (results['foundry_error'] or '') + f" Sensitive API error: {sensitive_result['error']}"
            else:
                results['sensitive_score'] = sensitive_result.get('score', 0.0)
                results['sensitive_indicators'] = sensitive_result.get('indicators', [])
                results['foundry_used'] = True

        # ---- Classification Logic ----
        classification, confidence, details_text = self._classify_results(results)

        # ---- Generate Recommendations ----
        recommendations = self._generate_recommendations(classification)

        return {
            'classification': classification,
            'confidence': confidence,
            'details': {
                'deepfake_score': results['deepfake_score'],
                'sensitive_score': results['sensitive_score'],
                'indicators': {
                    'manipulation': results['manipulation_indicators'],
                    'sensitive': results['sensitive_indicators']
                },
                'foundry_used': results['foundry_used'],
                'foundry_error': results['foundry_error']
            },
            'recommendations': recommendations
        }

    def _call_content_safety_api(self, img_bytes: bytes, analysis_type: str) -> Dict[str, Any]:
        """Call Microsoft Content Safety API for deepfake or sensitive analysis"""
        if not self.azure_content_safety_key or not self.azure_content_safety_endpoint:
            return {'error': 'Azure Content Safety Key/Endpoint not configured'}

        headers = {
            "Ocp-Apim-Subscription-Key": self.azure_content_safety_key,
            "Content-Type": "application/octet-stream"
        }

        try:
            response = requests.post(
                self.azure_content_safety_endpoint,
                headers=headers,
                data=img_bytes,
                timeout=15
            )
            response.raise_for_status()
            data = response.json()

            # Extract scores & indicators depending on analysis_type
            if analysis_type == 'deepfake':
                return {
                    'score': data.get('deepfake_score', 0.0),
                    'indicators': data.get('manipulation_indicators', [])
                }
            elif analysis_type == 'sensitive':
                return {
                    'score': data.get('sensitive_score', 0.0),
                    'indicators': data.get('sensitive_indicators', [])
                }
            else:
                return {'error': 'Unknown analysis_type'}

        except Exception as e:
            return {'error': str(e)}

    def _classify_results(self, results: Dict[str, Any]) -> tuple:
        """Classify media based on Microsoft AI scores"""
        deepfake_score = results['deepfake_score']
        sensitive_score = results['sensitive_score']

        if results['foundry_error']:
            return "unknown", 0.0, f"Foundry API error: {results['foundry_error']}"

        if deepfake_score > 50:
            classification = 'deepfake'
            confidence = min(deepfake_score, 98.0)
            details = "High likelihood of manipulation or deepfake"
        elif sensitive_score > 40:
            classification = 'sensitive'
            confidence = min(sensitive_score, 98.0)
            details = "Content appears to be sensitive/private"
        else:
            classification = 'real_safe'
            confidence = 98.0 - max(deepfake_score, sensitive_score)
            details = "Content appears authentic and safe"

        return classification, confidence, details

    def _generate_recommendations(self, classification: str) -> list:
        """Generate human-readable recommendations based on classification"""
        recommendations = []

        if classification == 'deepfake':
            recommendations.extend([
                "âš ï¸ This content shows signs of manipulation",
                "ğŸ” Verify source before sharing",
                "ğŸ›¡ï¸ Consider reporting if used maliciously"
            ])
        elif classification == 'sensitive':
            recommendations.extend([
                "ğŸ”’ This content may be sensitive",
                "ğŸ›¡ï¸ Consider generating protection fingerprint",
                "âš ï¸ Be cautious about sharing"
            ])
        else:
            recommendations.extend([
                "âœ… Content appears authentic",
                "ğŸ“ No immediate concerns detected"
            ])
        return recommendations
